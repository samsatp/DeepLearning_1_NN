{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import Value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Node\n",
    "represents one neuron node in a neural network which consists of weight vector and a bias.\n",
    "\n",
    "![](img/neuron.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, input_dim):\n",
    "        self.W = [Value(data=random.uniform(-1,1)) for _ in range(input_dim)]\n",
    "        self.b = Value(data=random.uniform(-1,1))\n",
    "\n",
    "    def __call__(self, xs):\n",
    "        assert len(xs) == len(self.W)  # Check for compatible dimension\n",
    "\n",
    "        out = sum([\n",
    "            w*x for w,x in zip(self.W, xs)\n",
    "        ]) + self.b\n",
    "        out = out.tanh()\n",
    "        return out\n",
    "\n",
    "    def params(self):\n",
    "        return self.W + [self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data = 0.45906528641408495)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_1 = Node(input_dim=5)\n",
    "xs = [random.uniform(-1,1) for _ in range(5)]\n",
    "node_1(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data = -0.7461006540499144),\n",
       " Value(data = 0.8433421933859226),\n",
       " Value(data = 0.681533261055298),\n",
       " Value(data = -0.477558888887901),\n",
       " Value(data = 0.061183070848930265),\n",
       " Value(data = -0.09748095399023304)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_1.params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Layer\n",
    "represents one layer in a neural network which consits of a weight matrix and a bias vector.\n",
    "\n",
    "![](img/layer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, input_dim, n_nodes):\n",
    "        self.nodes = [Node(input_dim=input_dim) for _ in range(n_nodes)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        out = [node(x) for node in self.nodes]\n",
    "        return out[0] if len(out) == 1 else out\n",
    "\n",
    "    def params(self):\n",
    "        return [p for node in self.nodes for p in node.params()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data = 0.09572270997160082),\n",
       " Value(data = -0.7745484499888353),\n",
       " Value(data = -0.9894731511999211),\n",
       " Value(data = 0.8513623338998093)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1 = Layer(input_dim=6, n_nodes=4)\n",
    "x = np.random.uniform(-1,1,size=6)\n",
    "layer_1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Value(data = 0.2823863813923855),\n",
       " Value(data = -0.35894616536645363),\n",
       " Value(data = 0.8987731327281889),\n",
       " Value(data = -0.5312090847557449),\n",
       " Value(data = -0.003877067284086877),\n",
       " Value(data = 0.3999014617542358),\n",
       " Value(data = 0.7582695569016693),\n",
       " Value(data = 0.4633769945367958),\n",
       " Value(data = -0.16258450319299),\n",
       " Value(data = 0.5879646666448408),\n",
       " Value(data = -0.11205771981453827),\n",
       " Value(data = -0.1634187164091403),\n",
       " Value(data = 0.8179747053420303),\n",
       " Value(data = -0.1354065448586892),\n",
       " Value(data = 0.1478561387491264),\n",
       " Value(data = -0.6909582640347618),\n",
       " Value(data = 0.8670658205603536),\n",
       " Value(data = 0.2794207445537986),\n",
       " Value(data = -0.7721593571477574),\n",
       " Value(data = 0.46505114843321915),\n",
       " Value(data = -0.7191050648166759),\n",
       " Value(data = 0.946734988089494),\n",
       " Value(data = 0.42892595078016016),\n",
       " Value(data = -0.0015078247216264717),\n",
       " Value(data = -0.20242724745158758),\n",
       " Value(data = 0.8666431783493653),\n",
       " Value(data = 0.07176173372224581),\n",
       " Value(data = 0.13024036510372317)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_1.params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multi-layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, input_dim, units):\n",
    "        unit_sizes = [input_dim] + units\n",
    "        self.layers = [Layer(input_dim=in_, n_nodes=unit) for in_, unit in zip(unit_sizes, units)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def params(self):\n",
    "        return [p for layer in self.layers for p in layer.params()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data = -0.1334353255861922)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [2.0, 3.0, -1.0]\n",
    "n = MLP(3, [4, 4, 1])\n",
    "n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(n.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "  [2.0, 3.0, -1.0],\n",
    "  [3.0, -1.0, 0.5],\n",
    "  [0.5, 1.0, 1.0],\n",
    "  [1.0, 1.0, -1.0],\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0] # desired targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.153783147818012\n",
      "1 4.193827708373865\n",
      "2 1.002408344331134\n",
      "3 0.1873538835987929\n",
      "4 0.0532064735255391\n",
      "5 0.04552733188608697\n",
      "6 0.03975141003023527\n",
      "7 0.03525448459197432\n",
      "8 0.03165800233204921\n",
      "9 0.028718866787141917\n",
      "10 0.02627381335478937\n",
      "11 0.024209164517735512\n",
      "12 0.022443380615314226\n",
      "13 0.020916494694134008\n",
      "14 0.019583453989458655\n",
      "15 0.018409779380068318\n",
      "16 0.017368653073929888\n",
      "17 0.016438915216654325\n",
      "18 0.015603655359900149\n",
      "19 0.014849202898201685\n"
     ]
    }
   ],
   "source": [
    "for k in range(20):\n",
    "  \n",
    "  # forward pass\n",
    "  ypred = [n(x) for x in xs]\n",
    "  loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n",
    "  \n",
    "  # backward pass\n",
    "  for p in n.params():\n",
    "    p.grad = 0.0\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  for p in n.params():\n",
    "    p.data += -0.1 * p.grad\n",
    "  \n",
    "  print(k, loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93d343a67186057eba7cc3f4fb38dbcf94a41bc6d951d30420561a381ab22bcf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
